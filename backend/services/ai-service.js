/**
 * AI æœåŠ¡è°ƒç”¨æ¨¡å—
 * 
 * ä½œç”¨ï¼š
 * 1. å°è£…å¯¹ AI API çš„è°ƒç”¨
 * 2. å¤„ç†è¯·æ±‚å’Œå“åº”
 * 3. é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
 * 4. æµå¼å“åº”å¤„ç†
 * 
 * ä½¿ç”¨åœºæ™¯ï¼š
 * - å°è¯´ç»­å†™
 * - å†…å®¹ç”Ÿæˆ
 * - åˆ›æ„æ‰©å±•
 */

import axios from 'axios'
import { GoogleAuth } from 'google-auth-library'
import { HttpsProxyAgent } from 'https-proxy-agent'
import fs from 'fs'
import { generateFullPrompt } from '../config/prompt-template.js'
import { 
  getCurrentAIConfig, 
  validateConfig, 
  buildVertexAIRequestBody,
  VERTEX_AI_CONFIG 
} from '../config/api-config.js'

/**
 * è·å– Google Cloud è®¿é—®ä»¤ç‰Œ
 * ä½¿ç”¨æœåŠ¡è´¦å· JSON å¯†é’¥æ–‡ä»¶è¿›è¡Œè®¤è¯
 * 
 * @param {string} credentialsPath - JSON å¯†é’¥æ–‡ä»¶è·¯å¾„
 * @returns {Promise<string>} è®¿é—®ä»¤ç‰Œ
 */
async function getGoogleAccessToken(credentialsPath) {
  try {
    // æ£€æŸ¥å¯†é’¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if (!fs.existsSync(credentialsPath)) {
      throw new Error(`å¯†é’¥æ–‡ä»¶ä¸å­˜åœ¨: ${credentialsPath}`)
    }

    // åˆ›å»ºè®¤è¯å®¢æˆ·ç«¯
    const auth = new GoogleAuth({
      keyFile: credentialsPath,
      scopes: ['https://www.googleapis.com/auth/cloud-platform']
    })

    // è·å–è®¿é—®ä»¤ç‰Œ
    const client = await auth.getClient()
    const token = await client.getAccessToken()
    
    if (!token.token) {
      throw new Error('æ— æ³•è·å–è®¿é—®ä»¤ç‰Œ')
    }

    return token.token
  } catch (error) {
    console.error('è·å– Google è®¿é—®ä»¤ç‰Œå¤±è´¥:', error.message)
    throw new Error(`è®¤è¯å¤±è´¥: ${error.message}`)
  }
}

/**
 * ä» JSON å¯†é’¥æ–‡ä»¶ä¸­è¯»å–é¡¹ç›® ID
 * 
 * @param {string} credentialsPath - JSON å¯†é’¥æ–‡ä»¶è·¯å¾„
 * @returns {string} é¡¹ç›® ID
 */
function getProjectIdFromCredentials(credentialsPath) {
  try {
    if (!fs.existsSync(credentialsPath)) {
      throw new Error(`å¯†é’¥æ–‡ä»¶ä¸å­˜åœ¨: ${credentialsPath}`)
    }

    const credentials = JSON.parse(fs.readFileSync(credentialsPath, 'utf8'))
    return credentials.project_id
  } catch (error) {
    console.error('è¯»å–é¡¹ç›® ID å¤±è´¥:', error.message)
    throw new Error(`æ— æ³•è¯»å–é¡¹ç›® ID: ${error.message}`)
  }
}

/**
 * ç”Ÿæˆå°è¯´å†…å®¹ï¼ˆä¸»å‡½æ•°ï¼‰
 * 
 * @param {Object} params - å‚æ•°å¯¹è±¡
 * @param {string} params.outline - å‰§æƒ…å¤§çº²
 * @param {Array} params.characters - äººç‰©å¡æ•°ç»„
 * @param {Array} params.items - ç‰©å“å¡æ•°ç»„
 * @param {Object} params.scene - åœºæ™¯å¡å¯¹è±¡
 * @param {string} params.previousContent - ä¹‹å‰çš„å†…å®¹ï¼ˆå¯é€‰ï¼‰
 * @param {number} params.targetWords - ç›®æ ‡å­—æ•°ï¼ˆå¯é€‰ï¼‰
 * @returns {Promise<Object>} ç”Ÿæˆç»“æœ
 */
async function generateNovelContent({
  outline,
  characters = [],
  items = [],
  scene = null,
  previousContent = '',
  targetWords = 2000
}) {
  try {
    // 1. éªŒè¯è¾“å…¥
    if (!outline || outline.trim() === '') {
      throw new Error('å‰§æƒ…å¤§çº²ä¸èƒ½ä¸ºç©º')
    }

    // 2. è·å– AI é…ç½®
    const aiConfig = getCurrentAIConfig()
    
    // 3. å¯¹äº Vertex AIï¼Œç¡®ä¿æœ‰ projectIdï¼ˆä»é…ç½®æˆ–å¯†é’¥æ–‡ä»¶è¯»å–ï¼‰
    if (aiConfig.name === 'Google Vertex AI') {
      if (!aiConfig.projectId) {
        // å°è¯•ä»å¯†é’¥æ–‡ä»¶è¯»å–
        try {
          aiConfig.projectId = getProjectIdFromCredentials(aiConfig.credentialsPath)
        } catch (error) {
          throw new Error(`æ— æ³•è·å–é¡¹ç›® ID: ${error.message}`)
        }
      }
    }

    console.log(`ğŸ¤– ä½¿ç”¨ AI æœåŠ¡: ${aiConfig.name}`)
    console.log(`ğŸ“ ç›®æ ‡å­—æ•°: ${targetWords} å­—`)

    // 3. ç”Ÿæˆå®Œæ•´æç¤ºè¯
    const fullPrompt = generateFullPrompt({
      outline,
      characters,
      items,
      scene,
      previousContent,
      targetWords
    })

    console.log('ğŸ“„ æç¤ºè¯é•¿åº¦:', fullPrompt.length, 'å­—ç¬¦')
    console.log('\n' + '='.repeat(80))
    console.log('ğŸ“ ç”Ÿæˆçš„å®Œæ•´æç¤ºè¯å†…å®¹')
    console.log('='.repeat(80))
    console.log(fullPrompt)
    console.log('='.repeat(80) + '\n')

    // 4. è°ƒç”¨ AI API
    let result
    if (aiConfig.name === 'Google Vertex AI') {
      result = await callVertexAI(fullPrompt, aiConfig)
    } else if (aiConfig.name === 'OpenAI') {
      result = await callOpenAI(fullPrompt, aiConfig)
    } else if (aiConfig.name === 'Claude') {
      result = await callClaude(fullPrompt, aiConfig)
    } else {
      throw new Error(`ä¸æ”¯æŒçš„ AI æœåŠ¡: ${aiConfig.name}`)
    }

    // 5. è¿”å›ç»“æœ
    console.log('\n' + '='.repeat(80))
    console.log('âœ¨ AI ç”Ÿæˆçš„å°è¯´å†…å®¹')
    console.log('='.repeat(80))
    console.log(result.content)
    console.log('='.repeat(80) + '\n')
    console.log('âœ… å†…å®¹ç”ŸæˆæˆåŠŸ')
    console.log('ğŸ“Š ç”Ÿæˆå­—æ•°:', result.content.length, 'å­—ç¬¦')
    console.log('ğŸ’° Token æ¶ˆè€—: è¾“å…¥', result.usage.promptTokens, '+ è¾“å‡º', result.usage.completionTokens, '= æ€»è®¡', result.usage.totalTokens, '\n')

    return {
      success: true,
      content: result.content,
      usage: result.usage,
      model: aiConfig.model.name
    }

  } catch (error) {
    console.error('âŒ ç”Ÿæˆå†…å®¹å¤±è´¥:', error.message)
    throw error
  }
}

/**
 * è°ƒç”¨ Google Vertex AI API
 * ä½¿ç”¨æœåŠ¡è´¦å·è®¤è¯
 * 
 * @param {string} prompt - æç¤ºè¯
 * @param {Object} config - AI é…ç½®
 * @returns {Promise<Object>} API å“åº”
 */
async function callVertexAI(prompt, config) {
  try {
    // 1. è·å–è®¿é—®ä»¤ç‰Œ
    console.log('ğŸ” æ­£åœ¨è·å–è®¿é—®ä»¤ç‰Œ...')
    const accessToken = await getGoogleAccessToken(config.credentialsPath)
    console.log('âœ… è®¿é—®ä»¤ç‰Œè·å–æˆåŠŸ')

    // 2. è·å–é¡¹ç›® IDï¼ˆä¼˜å…ˆä½¿ç”¨é…ç½®ä¸­çš„ï¼Œå¦åˆ™ä»å¯†é’¥æ–‡ä»¶è¯»å–ï¼‰
    const projectId = config.projectId || getProjectIdFromCredentials(config.credentialsPath)
    console.log('ğŸ“‹ é¡¹ç›® ID:', projectId)

    // 3. æ„å»º API ç«¯ç‚¹
    const endpoints = config.getEndpoint(projectId, config.location)
    const endpoint = endpoints.generateContent
    
    console.log('ğŸŒ API ç«¯ç‚¹:', endpoint)

    // 4. æ„å»ºè¯·æ±‚ä½“
    const requestBody = buildVertexAIRequestBody(prompt)

    // è¾“å‡ºå®Œæ•´çš„ API è¯·æ±‚ä¿¡æ¯
    console.log('\n' + '='.repeat(80))
    console.log('ğŸ“¤ å‘é€ç»™ Google Vertex AI çš„å®Œæ•´è¯·æ±‚')
    console.log('='.repeat(80))
    console.log('ğŸŒ è¯·æ±‚æ–¹æ³•: POST')
    console.log('ğŸŒ è¯·æ±‚ URL:', endpoint)
    console.log('\nğŸ“‹ è¯·æ±‚ Headers:')
    console.log(JSON.stringify({
      'Content-Type': 'application/json',
      'Authorization': 'Bearer [ACCESS_TOKEN]' // éšè—çœŸå® token
    }, null, 2))
    console.log('\nğŸ“¦ è¯·æ±‚ Body:')
    console.log(JSON.stringify(requestBody, null, 2))
    console.log('='.repeat(80) + '\n')

    // 5. é…ç½®è¯·æ±‚é€‰é¡¹ï¼ˆåŒ…æ‹¬ä»£ç†ï¼‰
    const axiosConfig = {
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${accessToken}`
      },
      timeout: config.timeout.response
    }

    // å¦‚æœç¯å¢ƒå˜é‡ä¸­æœ‰ä»£ç†é…ç½®ï¼Œä½¿ç”¨ä»£ç†ï¼ˆä¸­å›½ç½‘ç»œç¯å¢ƒå¿…éœ€ï¼‰
    const proxyUrl = process.env.HTTPS_PROXY || process.env.HTTP_PROXY
    if (proxyUrl) {
      console.log('ğŸ”„ ä½¿ç”¨ä»£ç†:', proxyUrl.replace(/\/\/[^@]*@/, '//***:***@')) // éšè—è®¤è¯ä¿¡æ¯
      axiosConfig.httpsAgent = new HttpsProxyAgent(proxyUrl)
      axiosConfig.proxy = false // ç¦ç”¨ axios é»˜è®¤ä»£ç†å¤„ç†
    } else {
      console.log('â„¹ï¸  æœªé…ç½®ä»£ç†ï¼Œç›´æ¥è¿æ¥ï¼ˆå¦‚æœåœ¨ä¸­å›½å¯èƒ½ä¼šå¤±è´¥ï¼‰')
    }

    // 6. å‘é€è¯·æ±‚
    const response = await axios.post(endpoint, requestBody, axiosConfig)

    console.log('ğŸ“¥ æ”¶åˆ°å“åº”')

    // 7. è§£æå“åº”
    if (!response.data || !response.data.candidates || response.data.candidates.length === 0) {
      console.error('âŒ API è¿”å›æ•°æ®:', JSON.stringify(response.data, null, 2))
      throw new Error('API è¿”å›æ•°æ®æ ¼å¼é”™è¯¯æˆ–ä¸ºç©º')
    }

    const candidate = response.data.candidates[0]
    const content = candidate.content?.parts?.[0]?.text || ''

    if (!content) {
      console.error('âŒ å€™é€‰å†…å®¹:', JSON.stringify(candidate, null, 2))
      throw new Error('API æœªè¿”å›æœ‰æ•ˆå†…å®¹')
    }

    // 8. æå– token ä½¿ç”¨ä¿¡æ¯
    const usage = {
      promptTokens: response.data.usageMetadata?.promptTokenCount || 0,
      completionTokens: response.data.usageMetadata?.candidatesTokenCount || 0,
      totalTokens: response.data.usageMetadata?.totalTokenCount || 0
    }

    // è¾“å‡ºå®Œæ•´çš„ API å“åº”ä¿¡æ¯
    console.log('\n' + '='.repeat(80))
    console.log('ğŸ“¥ Google Vertex AI è¿”å›çš„å®Œæ•´å“åº”')
    console.log('='.repeat(80))
    console.log('ğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡:')
    console.log(`   â”œâ”€ è¾“å…¥ Token (Input):  ${usage.promptTokens} tokens`)
    console.log(`   â”œâ”€ è¾“å‡º Token (Output): ${usage.completionTokens} tokens`)
    console.log(`   â””â”€ æ€»è®¡ Token (Total):  ${usage.totalTokens} tokens`)
    console.log('\nğŸ“ ç”Ÿæˆå†…å®¹é•¿åº¦:', content.trim().length, 'å­—ç¬¦')
    console.log('\nğŸ“„ å®Œæ•´å“åº”æ•°æ®:')
    console.log(JSON.stringify({
      candidates: response.data.candidates,
      usageMetadata: response.data.usageMetadata,
      modelVersion: response.data.modelVersion
    }, null, 2))
    console.log('='.repeat(80) + '\n')

    // 9. è¿”å›æ ‡å‡†åŒ–ç»“æœ
    return {
      content: content.trim(),
      usage: usage
    }

  } catch (error) {
    console.error('âŒ Vertex AI è°ƒç”¨å¤±è´¥:', error.response?.data || error.message)
    
    // å¤„ç†ç‰¹å®šé”™è¯¯
    if (error.response) {
      const status = error.response.status
      const errorData = error.response.data?.error
      const message = errorData?.message || error.message

      console.error('é”™è¯¯è¯¦æƒ…:', JSON.stringify(error.response.data, null, 2))

      if (status === 401) {
        throw new Error('API è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡è´¦å·å¯†é’¥æ˜¯å¦æ­£ç¡®')
      } else if (status === 403) {
        throw new Error(`API æƒé™ä¸è¶³: ${message}ã€‚è¯·ç¡®ä¿æœåŠ¡è´¦å·æœ‰ Vertex AI æƒé™`)
      } else if (status === 404) {
        throw new Error(`API ç«¯ç‚¹ä¸å­˜åœ¨: ${message}ã€‚è¯·æ£€æŸ¥æ¨¡å‹åç§°å’ŒåŒºåŸŸé…ç½®`)
      } else if (status === 429) {
        throw new Error('API è¯·æ±‚é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åé‡è¯•')
      } else if (status === 500) {
        throw new Error('AI æœåŠ¡å†…éƒ¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•')
      } else {
        throw new Error(`API é”™è¯¯ (${status}): ${message}`)
      }
    }

    throw error
  }
}

/**
 * è°ƒç”¨ Vertex AI æµå¼ APIï¼ˆé«˜çº§åŠŸèƒ½ï¼‰
 * ç”¨äºå®æ—¶è¿”å›ç”Ÿæˆå†…å®¹ï¼Œæå‡ç”¨æˆ·ä½“éªŒ
 * 
 * @param {string} prompt - æç¤ºè¯
 * @param {Object} config - AI é…ç½®
 * @param {Function} onChunk - æ¥æ”¶åˆ°æ•°æ®å—æ—¶çš„å›è°ƒå‡½æ•°
 * @returns {Promise<Object>} å®Œæ•´å“åº”
 */
async function callVertexAIStream(prompt, config, onChunk) {
  try {
    // æ„å»ºæµå¼ç«¯ç‚¹
    const endpoint = `https://aiplatform.googleapis.com/v1/projects/${config.projectId}/locations/${config.location}/${config.model.fullPath}:streamGenerateContent`
    
    console.log('ğŸŒŠ ä½¿ç”¨æµå¼ API:', endpoint)

    // æ„å»ºè¯·æ±‚ä½“
    const requestBody = buildVertexAIRequestBody(prompt)

    // å‘é€æµå¼è¯·æ±‚
    const response = await axios.post(endpoint, requestBody, {
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${config.apiKey}`
      },
      responseType: 'stream',
      timeout: config.timeout.response
    })

    let fullContent = ''
    let usage = {}

    // å¤„ç†æµå¼æ•°æ®
    return new Promise((resolve, reject) => {
      response.data.on('data', (chunk) => {
        try {
          // è§£ææ•°æ®å—
          const lines = chunk.toString().split('\n').filter(line => line.trim())
          
          for (const line of lines) {
            if (line.startsWith('data: ')) {
              const jsonStr = line.slice(6) // ç§»é™¤ "data: " å‰ç¼€
              const data = JSON.parse(jsonStr)
              
              if (data.candidates && data.candidates[0]) {
                const text = data.candidates[0].content?.parts?.[0]?.text || ''
                if (text) {
                  fullContent += text
                  // å›è°ƒå‡½æ•°ï¼Œå®æ—¶è¿”å›æ•°æ®å—
                  if (onChunk) {
                    onChunk(text)
                  }
                }
              }

              // è®°å½• token ä½¿ç”¨æƒ…å†µ
              if (data.usageMetadata) {
                usage = {
                  promptTokens: data.usageMetadata.promptTokenCount || 0,
                  completionTokens: data.usageMetadata.candidatesTokenCount || 0,
                  totalTokens: data.usageMetadata.totalTokenCount || 0
                }
              }
            }
          }
        } catch (err) {
          console.error('è§£ææµå¼æ•°æ®å¤±è´¥:', err)
        }
      })

      response.data.on('end', () => {
        resolve({
          content: fullContent.trim(),
          usage
        })
      })

      response.data.on('error', (err) => {
        reject(new Error(`æµå¼ä¼ è¾“é”™è¯¯: ${err.message}`))
      })
    })

  } catch (error) {
    console.error('Vertex AI æµå¼è°ƒç”¨å¤±è´¥:', error.message)
    throw error
  }
}

/**
 * è°ƒç”¨ OpenAI APIï¼ˆé¢„ç•™ï¼‰
 * 
 * @param {string} prompt - æç¤ºè¯
 * @param {Object} config - AI é…ç½®
 * @returns {Promise<Object>} API å“åº”
 */
async function callOpenAI(prompt, config) {
  try {
    const response = await axios.post(
      config.endpoint.chatCompletion,
      {
        model: config.model.name,
        messages: [
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: config.parameters.temperature,
        max_tokens: config.parameters.maxTokens,
        top_p: config.parameters.topP
      },
      {
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${config.apiKey}`
        }
      }
    )

    const content = response.data.choices[0].message.content

    return {
      content: content.trim(),
      usage: {
        promptTokens: response.data.usage.prompt_tokens,
        completionTokens: response.data.usage.completion_tokens,
        totalTokens: response.data.usage.total_tokens
      }
    }
  } catch (error) {
    console.error('OpenAI è°ƒç”¨å¤±è´¥:', error.message)
    throw error
  }
}

/**
 * è°ƒç”¨ Claude APIï¼ˆé¢„ç•™ï¼‰
 * 
 * @param {string} prompt - æç¤ºè¯
 * @param {Object} config - AI é…ç½®
 * @returns {Promise<Object>} API å“åº”
 */
async function callClaude(prompt, config) {
  try {
    const response = await axios.post(
      config.endpoint.messages,
      {
        model: config.model.name,
        messages: [
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: config.parameters.maxTokens,
        temperature: config.parameters.temperature
      },
      {
        headers: {
          'Content-Type': 'application/json',
          'x-api-key': config.apiKey,
          'anthropic-version': '2023-06-01'
        }
      }
    )

    const content = response.data.content[0].text

    return {
      content: content.trim(),
      usage: {
        promptTokens: response.data.usage.input_tokens,
        completionTokens: response.data.usage.output_tokens,
        totalTokens: response.data.usage.input_tokens + response.data.usage.output_tokens
      }
    }
  } catch (error) {
    console.error('Claude è°ƒç”¨å¤±è´¥:', error.message)
    throw error
  }
}

/**
 * å¸¦é‡è¯•æœºåˆ¶çš„ API è°ƒç”¨
 * ç”¨äºæé«˜è°ƒç”¨æˆåŠŸç‡
 * 
 * @param {Function} apiCall - API è°ƒç”¨å‡½æ•°
 * @param {number} maxRetries - æœ€å¤§é‡è¯•æ¬¡æ•°
 * @param {number} delay - é‡è¯•å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
 * @returns {Promise<Object>} API å“åº”
 */
async function callWithRetry(apiCall, maxRetries = 3, delay = 1000) {
  let lastError

  for (let i = 0; i < maxRetries; i++) {
    try {
      return await apiCall()
    } catch (error) {
      lastError = error
      console.log(`âš ï¸ ç¬¬ ${i + 1} æ¬¡å°è¯•å¤±è´¥ï¼Œ${delay}ms åé‡è¯•...`)
      
      // å¦‚æœæ˜¯è®¤è¯é”™è¯¯æˆ–å‚æ•°é”™è¯¯ï¼Œä¸é‡è¯•
      if (error.message.includes('è®¤è¯') || error.message.includes('å‚æ•°')) {
        throw error
      }

      // ç­‰å¾…åé‡è¯•
      await new Promise(resolve => setTimeout(resolve, delay))
      delay *= 2 // æŒ‡æ•°é€€é¿
    }
  }

  throw lastError
}

/**
 * æµ‹è¯• AI è¿æ¥
 * ç”¨äºéªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®
 * 
 * @returns {Promise<Object>} æµ‹è¯•ç»“æœ
 */
async function testConnection() {
  try {
    const config = getCurrentAIConfig()
    
    console.log('ğŸ“‹ éªŒè¯é…ç½®...')
    
    // éªŒè¯é…ç½®ï¼ˆå…è®¸ projectId ä¸ºç©ºï¼Œå› ä¸ºå¯ä»¥ä»å¯†é’¥æ–‡ä»¶è¯»å–ï¼‰
    if (!config.credentialsPath) {
      return {
        success: false,
        message: 'ç¼ºå°‘ Google Cloud å¯†é’¥æ–‡ä»¶è·¯å¾„'
      }
    }

    // æ£€æŸ¥å¯†é’¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if (!fs.existsSync(config.credentialsPath)) {
      return {
        success: false,
        message: `å¯†é’¥æ–‡ä»¶ä¸å­˜åœ¨: ${config.credentialsPath}`
      }
    }

    console.log('âœ… å¯†é’¥æ–‡ä»¶å­˜åœ¨:', config.credentialsPath)

    // å°è¯•è¯»å–é¡¹ç›® ID
    try {
      const projectId = config.projectId || getProjectIdFromCredentials(config.credentialsPath)
      console.log('âœ… é¡¹ç›® ID:', projectId)
    } catch (error) {
      return {
        success: false,
        message: `æ— æ³•è¯»å–é¡¹ç›® ID: ${error.message}`
      }
    }

    // å‘é€ç®€å•çš„æµ‹è¯•è¯·æ±‚
    console.log('ğŸ§ª å‘é€æµ‹è¯•è¯·æ±‚...')
    const testPrompt = 'è¯·ç”¨ä¸­æ–‡å›å¤"æµ‹è¯•æˆåŠŸ"å››ä¸ªå­—ã€‚'
    const result = await callVertexAI(testPrompt, config)

    return {
      success: true,
      message: 'è¿æ¥æˆåŠŸ',
      model: config.model.name,
      response: result.content,
      usage: result.usage
    }
  } catch (error) {
    return {
      success: false,
      message: `è¿æ¥å¤±è´¥: ${error.message}`
    }
  }
}

/**
 * å¯¼å‡ºå‡½æ•°
 */
export {
  generateNovelContent,
  callVertexAI,
  callVertexAIStream,
  callWithRetry,
  testConnection
}

export default {
  generateNovelContent,
  callVertexAI,
  callVertexAIStream,
  callWithRetry,
  testConnection
}

